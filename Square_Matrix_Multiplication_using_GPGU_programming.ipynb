{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "See original notebook : https://drive.google.com/drive/folders/1n0uyo6ZnAsg3eB3n8wFKrL6XPL54ctuG?usp=share_link"
      ],
      "metadata": {
        "id": "oJXIPVeb1EFQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwd38XvZK2sy"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6ewR7_sHJ00",
        "outputId": "e82d8421-7047-4758-8f7b-9b9e7ee619ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn2s4LVCHL0J",
        "outputId": "a8d76f3b-bf48-41e4-80ef-146f6055e88e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/frehseg/nvcc4jupyter.git\n",
            "  Cloning https://github.com/frehseg/nvcc4jupyter.git to /tmp/pip-req-build-923e9rz1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/frehseg/nvcc4jupyter.git /tmp/pip-req-build-923e9rz1\n",
            "  Resolved https://github.com/frehseg/nvcc4jupyter.git to commit a599751b98cbb8537fe9609198030b55669535da\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.2-py3-none-any.whl size=2192 sha256=f8ebdd1b184537739b626bd3ad6fd9c576ab1d715564bbeb90d84b01c7c5bfc0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vscs5yqh/wheels/4c/02/de/02070cb0bea5e90c8e1412113a24c8967f93b63f8806e2b398\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade git+https://github.com/frehseg/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoKiUawdHMGn"
      },
      "outputs": [],
      "source": [
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM903nhRJ6zm",
        "outputId": "59e9e86d-f468-48d8-bcc0-252e11413d9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import os\n",
        "os.environ['PATH'].split(';')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cweMlOB0L4mG"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po-TEvrWMJ_a"
      },
      "source": [
        "## CUDA Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-lgwhE1N5_7",
        "outputId": "68d93eed-af0e-4737-ff4b-852b0c50a5a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_stuff.cuh\n"
          ]
        }
      ],
      "source": [
        "%%writefile cuda_stuff.cuh\n",
        "#ifndef cuda_stuff_H\n",
        "#define cuda_stuff_H\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "//MACRO TO DEBUG CUDA FUNCTIONS\n",
        "/** Error checking,\n",
        " *  taken from https://stackoverflow.com/questions/14038589/what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api\n",
        " */\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess) \n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "\n",
        "void device_synchronize();\n",
        "\n",
        "#endif\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iivrxLaYOYPh",
        "outputId": "934cbad4-ec36-4b4e-8fcf-4249dfca6d38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_stuff.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile cuda_stuff.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#include \"cuda_stuff.cuh\"\n",
        "\n",
        "void device_synchronize(){\n",
        "    gpuErrchk(cudaDeviceSynchronize());\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fsEMpauK8lW"
      },
      "source": [
        "## Matrix Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A97U902HMog4",
        "outputId": "f72b4cca-d99a-46d5-b3ba-ddc84f849509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing fmatrix.cuh\n"
          ]
        }
      ],
      "source": [
        "%%writefile fmatrix.cuh\n",
        "#ifndef fmatrices_H\n",
        "#define fmatrices_H\n",
        "#include <stddef.h> \n",
        "\n",
        "typedef struct {\n",
        "    float* data;\n",
        "    size_t cols;\n",
        "    size_t rows;\n",
        "} fmatrix;\n",
        "\n",
        "/* transform matrix index to vector offset\n",
        "   Since CUDA uses column major, \n",
        "   nb_rows = number of rows */\n",
        "#define IDX2C(i,j,nb_rows) (((j)*(nb_rows))+(i))\n",
        "\n",
        "/* Access element (i,j) of matrix mat */\n",
        "#define getfm(mat,i,j) (mat.data[IDX2C(i,j,mat.rows)])\n",
        "\n",
        "\n",
        "size_t fmatrix_elements(fmatrix mat);\n",
        "size_t fmatrix_size(fmatrix mat);\n",
        "void fmatrix_init(fmatrix mat, float f);\n",
        "/** Assert that the matrix is coherent: all fields nonzero. */\n",
        "void fmatrix_assert();\n",
        "\n",
        "fmatrix fmatrix_create_on_host(size_t rows, size_t cols);\n",
        "fmatrix fmatrix_create_on_device(size_t rows, size_t cols);\n",
        "\n",
        "void fmatrix_data_to_host(fmatrix mat_host, fmatrix mat_device);\n",
        "void fmatrix_data_to_device(fmatrix mat_host, fmatrix mat_device);\n",
        "\n",
        "void fmatrix_free_on_host(fmatrix* mat);\n",
        "void fmatrix_free_on_device(fmatrix* mat);\n",
        "\n",
        "/** Print the first nb rows of the matrix mat\n",
        " *  on the host. \n",
        " *  If nb<0, print all rows. \n",
        " */\n",
        "void fmatrix_host_print(fmatrix mat, int nb=-1);\n",
        "\n",
        "/** Print the first nb rows of the matrix mat\n",
        " *  on the device. \n",
        " *  If nb<0, print all rows. \n",
        " */\n",
        "void fmatrix_device_print(fmatrix mat, int nb=-1);\n",
        "\n",
        "#endif\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGwZ36ifWQ-d",
        "outputId": "17b93cbd-dc07-4cce-dfb4-0f8c42ecb2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing fmatrix.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile fmatrix.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#include \"cuda_stuff.cuh\"\n",
        "#include \"fmatrix.cuh\"\n",
        "\n",
        "size_t fmatrix_elements(fmatrix mat) {\n",
        "     return mat.cols*mat.rows;\n",
        "}\n",
        "\n",
        "size_t fmatrix_size(fmatrix mat) {\n",
        "     return fmatrix_elements(mat) * sizeof(mat.data[0]);\n",
        "}\n",
        "\n",
        "void fmatrix_init(fmatrix mat, float f) {\n",
        "    for (int i = 0; i < mat.rows; i++){\n",
        "        for (int j = 0; j < mat.cols; j++){\n",
        "            mat.data[IDX2C(i,j,mat.rows)] = f; \n",
        "    }\n",
        "  }\n",
        "} \n",
        "\n",
        "void fmatrix_assert(fmatrix mat) {\n",
        "    assert(mat.data);\n",
        "    assert(mat.cols);\n",
        "    assert(mat.rows);\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "fmatrix fmatrix_create_on_host(size_t rows, size_t cols) {\n",
        "    assert(cols>0);\n",
        "    assert(rows>0);\n",
        "    fmatrix mat;\n",
        "    mat.cols = cols;\n",
        "    mat.rows = rows;\n",
        "    mat.data = (float*)malloc(fmatrix_size(mat)); \n",
        "    assert(mat.data);\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_on_device(size_t rows, size_t cols) {\n",
        "    assert(cols>0);\n",
        "    assert(rows>0);\n",
        "    fmatrix mat;\n",
        "    mat.cols = cols;\n",
        "    mat.rows = rows;\n",
        "    gpuErrchk( \n",
        "        cudaMalloc((void **)&(mat.data), fmatrix_size(mat)) \n",
        "    );\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "void fmatrix_data_to_device(fmatrix mat_host, fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix_assert(mat_device);\n",
        "    assert(mat_host.cols==mat_device.cols);\n",
        "    assert(mat_host.rows==mat_device.rows);\n",
        "    gpuErrchk( \n",
        "        cudaMemcpy( mat_device.data, mat_host.data, \n",
        "                   fmatrix_size(mat_host), \n",
        "                   cudaMemcpyHostToDevice \n",
        "                   )\n",
        "        );\n",
        "}\n",
        "\n",
        "void fmatrix_data_to_host(fmatrix mat_host, fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix_assert(mat_device);\n",
        "    assert(mat_host.cols==mat_device.cols);\n",
        "    assert(mat_host.rows==mat_device.rows);\n",
        "    gpuErrchk(\n",
        "        cudaMemcpy( mat_host.data, mat_device.data,  \n",
        "                   fmatrix_size(mat_device), \n",
        "                   cudaMemcpyDeviceToHost \n",
        "                   )\n",
        "        );\n",
        "}\n",
        "\n",
        "void fmatrix_free_on_host(fmatrix* mat) {\n",
        "    fmatrix_assert(*mat);  \n",
        "  free(mat->data);\n",
        "  mat->data = 0;\n",
        "  mat->cols = 0;\n",
        "  mat->rows = 0;\n",
        "}\n",
        "\n",
        "void fmatrix_free_on_device(fmatrix* mat) {\n",
        "    fmatrix_assert(*mat);  \n",
        "  gpuErrchk(cudaFree(mat->data));\n",
        "  mat->data = 0;\n",
        "  mat->cols = 0;\n",
        "  mat->rows = 0;\n",
        "}\n",
        "\n",
        "void fmatrix_host_print(fmatrix mat, int nb){\n",
        "    if (nb<0 || nb > mat.rows) {\n",
        "        nb = mat.rows;\n",
        "    }\n",
        "    printf(\"[\\n\");\n",
        "    for (int i = 0 ; i < nb; i++){\n",
        "      for (int j = 0 ; j<mat.cols; j++){\n",
        "        printf(\"%f\", getfm(mat,i,j));\n",
        "        if (j+1<mat.cols) {\n",
        "          printf(\",\\t\");\n",
        "        }\n",
        "      }\n",
        "      if (i+1<nb) {\n",
        "        printf(\";\\n\");\n",
        "      }\n",
        "    }\n",
        "    if (nb < mat.rows) {\n",
        "      printf(\"\\n...\\n\");\n",
        "    }\n",
        "  printf(\"\\n]\\n\");\n",
        "}\n",
        "\n",
        "void fmatrix_device_print(fmatrix mat, int nb){\n",
        "   // allocate copy\n",
        "   fmatrix tmp = fmatrix_create_on_host(mat.rows, mat.cols);\n",
        "   fmatrix_data_to_host(tmp, mat);\n",
        "   fmatrix_host_print(tmp,nb);\n",
        "   fmatrix_free_on_host(&tmp);\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM266RRGjwUH"
      },
      "source": [
        "## Matrix Math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNjf6dkCfh9t",
        "outputId": "8b523938-2e1f-403e-b4fb-a4946f4335eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sgemm.cuh\n"
          ]
        }
      ],
      "source": [
        "%%writefile sgemm.cuh\n",
        "#ifndef sgemm_H\n",
        "#define sgemm_H\n",
        "\n",
        "#include <string>\n",
        "#include \"fmatrix.cuh\"\n",
        "\n",
        "void mat_mul(fmatrix A, fmatrix B, fmatrix C, std::string arg);\n",
        "\n",
        "#endif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOBsNcM0foDD",
        "outputId": "4b98bc6b-748b-415b-cf7e-e79c064b504d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sgemm.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile sgemm.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string>\n",
        "#include <time.h>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include \"cublas_v2.h\"\n",
        "\n",
        "#include \"cuda_stuff.cuh\"\n",
        "#include \"sgemm.cuh\"\n",
        "#include \"fmatrix.cuh\"\n",
        "\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "#define TILE_WIDTH 32\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/* TODO : basic matrix multiplication C = alpha*A*B + beta*C on host as reference for the speedup */\n",
        "void matrixMultiplication_basic_host(float alpha, fmatrix A, fmatrix B, float beta, fmatrix C) { \n",
        "  float tmp = 0;\n",
        "  for (int i = 0; i<A.rows; i++){\n",
        "    for (int j = 0; j<B.cols; j++){\n",
        "      for (int k = 0; k<A.cols; k++){\n",
        "        tmp += alpha * getfm(A,i, k) * getfm(B, k, j);\n",
        "      }\n",
        "      C.data[IDX2C(i,j,C.rows)] = beta * C.data[IDX2C(i,j,C.rows)] + tmp; \n",
        "      tmp = 0;\n",
        "    }\n",
        "  } \n",
        "}\n",
        "               \n",
        "/* TODO : 3 different versions of matrix multiplication C = alpha*A*B + beta*C on device */\n",
        "__global__\n",
        "void matmul_basic_kernel(float *A, float *B, float *C, int nb_ColA, int nb_ColB, int nb_LigneA, int nb_LigneB) {\n",
        " /* TODO */\n",
        " float tmp = 0;\n",
        " int row = blockIdx.x;\n",
        " int col = threadIdx.x;\n",
        "  for (int i = 0; i < nb_ColA; i++) {\n",
        "      tmp += A[i * nb_LigneA + row] * B[col * nb_LigneB + i];\n",
        " }\n",
        " C[col * nb_LigneA + row] = tmp;\n",
        "}\n",
        "void matrixMultiplication_basic(float alpha, fmatrix d_A, fmatrix d_B, float beta, fmatrix d_C) { \n",
        "  // TODO : declaration of dimGrid and dimBlock\n",
        "  int dimGrid=d_A.rows;\n",
        "  int dimBlock=d_A.rows;\n",
        "  \n",
        "  matmul_basic_kernel <<< dimGrid, dimBlock >>> (d_A.data, d_B.data, d_C.data, d_A.cols, d_B.cols, d_A.rows, d_B.rows);\n",
        "\n",
        "} \n",
        "\n",
        "/**********************/\n",
        "__global__\n",
        "void matmul_tiled_kernel(float *A, float *B, float *C, int nb_ColA, int nb_ColB, int nb_LigneA, int nb_LigneB){\n",
        "  const int tile_width=16;\n",
        "  int N=nb_LigneA/tile_width;\n",
        "  int i=threadIdx.x/tile_width;\n",
        "  int j=threadIdx.x-i*tile_width;\n",
        "  int row=blockIdx.x/N;\n",
        "  int col=blockIdx.x-row*N;\n",
        "  __shared__ int sharedA[tile_width*tile_width];\n",
        "  __shared__ int sharedB[tile_width*tile_width];\n",
        "  for (int n = 0; n < N; n++){\n",
        "      sharedB[j*tile_width+i]=B[(j+tile_width*col)*nb_LigneB+(i+tile_width*n)];\n",
        "      sharedA[j*tile_width+i]=A[(j+tile_width*n)*nb_LigneA+(i+tile_width*row)];\n",
        "      __syncthreads();\n",
        "      float tmp=0;\n",
        "      for (int k = 0; k < tile_width; k++){\n",
        "          tmp += sharedA[k*tile_width+i]*sharedB[j*tile_width+k];\n",
        "      }\n",
        "      C[(j+tile_width*col)*nb_LigneA+(i+tile_width*row)]=C[(j+tile_width*col)*nb_LigneA+(i+tile_width*row)]+tmp;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "void matrixMultiplication_tiled(float alpha, fmatrix d_A, fmatrix d_B, float beta, fmatrix d_C){\n",
        "  // TODO : declaration of dimGrid and dimBlock\n",
        "  const int tile_width=16;\n",
        "  int N=d_A.rows/tile_width;\n",
        "  int dimGrid=N*N;\n",
        "  int dimBlock=tile_width*tile_width;\n",
        "  matmul_tiled_kernel <<< dimGrid, dimBlock >>> (d_A.data, d_B.data, d_C.data, d_A.cols, d_B.cols, d_A.rows, d_B.rows);\n",
        "}\n",
        "\n",
        "/**********************/\n",
        "void matrixMultiplication_cublas(float alpha, fmatrix d_A, fmatrix d_B, float beta, fmatrix d_C){\n",
        "  cublasHandle_t handle;\n",
        "  cublasCreate(&handle);\n",
        "  int m=d_A.rows;\n",
        "  int n=d_B.cols;\n",
        "  int k=d_A.cols;\n",
        "  cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, m, n, k, &alpha, d_A.data, m, d_B.data, k, &beta, d_C.data, m);\n",
        "  cublasDestroy(handle);\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "/*MAIN SGEMM*/\n",
        "void gen_mat_mul(float alpha, fmatrix A, fmatrix B, float beta, fmatrix C, std::string arg){\n",
        "    if (arg == \"cpu\"){\n",
        "        matrixMultiplication_basic_host(alpha, A, B, beta, C);\n",
        "    } else {\n",
        "      /* kernel function*/  \n",
        "      if (arg == \"gpu_basic\"){\n",
        "          matrixMultiplication_basic(alpha, A, B, beta, C);\n",
        "      \n",
        "      } else if (arg == \"gpu_tiled\"){\n",
        "          matrixMultiplication_tiled(alpha, A, B, beta, C);\n",
        "      \n",
        "      } else if (arg == \"gpu_cublas\"){\n",
        "         matrixMultiplication_cublas(alpha, A, B, beta, C);\n",
        "    \n",
        "      } else{\n",
        "          printf(\"Matrix Multiplication argument is Wrong\");\n",
        "          exit(0);\n",
        "      }\n",
        "      // wait for everything to finish\n",
        "      printf(\"Synchro\\n\");\n",
        "      device_synchronize();\n",
        "    }\n",
        "}\n",
        "\n",
        "void mat_mul(fmatrix A, fmatrix B, fmatrix C, std::string arg){\n",
        " gen_mat_mul(1.0, A, B, 0.1, C, arg);   \n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnpSu2wH2ooy"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWEplkuA2Ygf",
        "outputId": "a5d5479e-9102-4a49-f9a7-92d48b00113b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"sgemm.cuh\"\n",
        "\n",
        "#define TILE_WIDTH 32\n",
        "#define SIZE 20\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  /* Allocate and initialize data on host */\n",
        "  fmatrix A = fmatrix_create_on_host(TILE_WIDTH * SIZE, TILE_WIDTH * SIZE);\n",
        "  fmatrix_init(A, 1.0);    \n",
        "  fmatrix B = fmatrix_create_on_host(TILE_WIDTH * SIZE, TILE_WIDTH * SIZE);\n",
        "  fmatrix_init(B, 2.0);\n",
        "  fmatrix C = fmatrix_create_on_host(TILE_WIDTH * SIZE, TILE_WIDTH * SIZE);\n",
        "  fmatrix_init(C, 0.0);\n",
        "\n",
        "  /* Allocate data on device */\n",
        "  fmatrix d_A = fmatrix_create_on_device(TILE_WIDTH * SIZE, TILE_WIDTH * SIZE);\n",
        "  fmatrix d_B = fmatrix_create_on_device(TILE_WIDTH * SIZE, TILE_WIDTH * SIZE);\n",
        "  fmatrix d_C = fmatrix_create_on_device(TILE_WIDTH * SIZE, TILE_WIDTH * SIZE);\n",
        "  \n",
        "  /* Transfer A and B on device */\n",
        "  fmatrix_data_to_device(A, d_A);\n",
        "  fmatrix_data_to_device(B, d_B); \n",
        "  fmatrix_data_to_device(C, d_C);\n",
        "\n",
        "  clock_t start, end;\n",
        "  float cpu_time_used;   \n",
        "\n",
        "  /* Start calculation \"cpu\", \"gpu_basic\", \"gpu_tiled\", \"gpu_cublas\" */ \n",
        "  /************** \"cpu\" *******************/\n",
        "  start = clock();\n",
        "  mat_mul(A, B, C, \"cpu\");\n",
        "  end = clock();\n",
        "  cpu_time_used = ((double) (end - start)) * 1000 / CLOCKS_PER_SEC;\n",
        "  printf(\"Time taken by CPU in milliseconds: %.2f\\n\", cpu_time_used);\n",
        " \n",
        "  \n",
        "  /* Result correctness */\n",
        "  {\n",
        "    float maxError = 0.0f;\n",
        "    for (int i = 0; i < TILE_WIDTH * SIZE; i++){\n",
        "      for (int j = 0; j < TILE_WIDTH * SIZE; j++){\n",
        "        maxError = max(maxError, abs(getfm(C,i,j)- 2*TILE_WIDTH * SIZE));\n",
        "      }\n",
        "    } \n",
        "    printf(\"Max error: %f\\n\", maxError);\n",
        "  }\n",
        "  fmatrix_init(C, 0.0); \n",
        "\n",
        "  /************** \"gpu_basic\" *******************/\n",
        "  start = clock();\n",
        "  mat_mul(d_A, d_B, d_C, \"gpu_basic\");\n",
        "  end = clock();\n",
        "  cpu_time_used = ((double) (end - start)) * 1000 / CLOCKS_PER_SEC;\n",
        "  printf(\"GPU basic matrix multiplication in milliseconcs : %.2f\\n\", cpu_time_used);\n",
        " \n",
        "  /* Retrieve the result */\n",
        "  fmatrix_data_to_host(C, d_C);\n",
        "  /* Result correctness */\n",
        "  {\n",
        "    float maxError = 0.0f;\n",
        "    for (int i = 0; i < TILE_WIDTH * SIZE; i++){\n",
        "      for (int j = 0; j < TILE_WIDTH * SIZE; j++){\n",
        "        maxError = max(maxError, abs(getfm(C,i,j)- 2*TILE_WIDTH * SIZE));\n",
        "      }\n",
        "    }   \n",
        "    printf(\"Max error: %f\\n\", maxError);\n",
        "  } \n",
        "  fmatrix_init(C, 0.0); \n",
        "  fmatrix_data_to_device(C, d_C);\n",
        " \n",
        "\n",
        " /************** \"gpu_tiled\" *******************/\n",
        "  start = clock();\n",
        "  mat_mul(d_A, d_B, d_C, \"gpu_tiled\");\n",
        "  end = clock();\n",
        "  cpu_time_used = ((double) (end - start)) * 1000 / CLOCKS_PER_SEC;\n",
        "  printf(\"GPU tiled matrix multiplication in milliseconcs : %.2f\\n\", cpu_time_used);\n",
        " \n",
        "  /* Retrieve the result */\n",
        "  fmatrix_data_to_host(C, d_C);\n",
        "  /* Result correctness */\n",
        "  {\n",
        "    float maxError = 0.0f;\n",
        "    for (int i = 0; i < TILE_WIDTH * SIZE; i++){\n",
        "      for (int j = 0; j < TILE_WIDTH * SIZE; j++){\n",
        "        maxError = max(maxError, abs(getfm(C,i,j)- 2*TILE_WIDTH * SIZE));\n",
        "      }\n",
        "    }   \n",
        "    printf(\"Max error: %f\\n\", maxError);\n",
        "  } \n",
        "  fmatrix_init(C, 0.0); \n",
        "  fmatrix_data_to_device(C, d_C);\n",
        "\n",
        "\n",
        "  /************** \"gpu_cublas\" *******************/\n",
        "  start = clock();\n",
        "  mat_mul(d_A, d_B, d_C, \"gpu_cublas\");\n",
        "  end = clock();\n",
        " \n",
        "  cpu_time_used = ((double) (end - start)) * 1000 / CLOCKS_PER_SEC;\n",
        "  printf(\"GPU cuBLAS matrix multiplication in milliseconcs : %.2f\\n\", cpu_time_used);\n",
        " \n",
        "  /* Retrieve the result */\n",
        "  fmatrix_data_to_host(C, d_C);\n",
        "  /* Result correctness */\n",
        "  {\n",
        "    float maxError = 0.0f;\n",
        "    for (int i = 0; i < TILE_WIDTH * SIZE; i++){\n",
        "      for (int j = 0; j < TILE_WIDTH * SIZE; j++){\n",
        "        maxError = max(maxError, abs(getfm(C,i,j)- 2*TILE_WIDTH * SIZE));\n",
        "      }\n",
        "    }   \n",
        "    printf(\"Max error: %f\\n\", maxError);\n",
        "  } \n",
        "  fmatrix_init(C, 0.0); \n",
        "  fmatrix_data_to_device(C, d_C);\n",
        "\n",
        "  /* Free */ \n",
        "  fmatrix_free_on_host(&A);\n",
        "  fmatrix_free_on_host(&B);\n",
        "  fmatrix_free_on_host(&C);\n",
        "  fmatrix_free_on_device(&d_A);\n",
        "  fmatrix_free_on_device(&d_B);\n",
        "  fmatrix_free_on_device(&d_C);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrATC8s9LsDw"
      },
      "source": [
        "# Compiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z52xd0NMRKXb"
      },
      "outputs": [],
      "source": [
        "!nvcc  -lcublas sgemm.cu  fmatrix.cu  cuda_stuff.cu main.cu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZVqTfXcLvPr"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_D8hNmXwi0S",
        "outputId": "91b5f36a-5fd5-4b51-db17-2da4f1eba0d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken by CPU in milliseconds: 1468.98\n",
            "Max error: 0.000000\n",
            "Synchro\n",
            "GPU basic matrix multiplication in milliseconcs : 23.92\n",
            "Max error: 0.000000\n",
            "Synchro\n",
            "GPU tiled matrix multiplication in milliseconcs : 7.16\n",
            "Max error: 0.000000\n",
            "Synchro\n",
            "GPU cuBLAS matrix multiplication in milliseconcs : 703.57\n",
            "Max error: 0.000000\n"
          ]
        }
      ],
      "source": [
        "! ./a.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ8nAtzGTRgH",
        "outputId": "64bf29e1-7e04-48cc-9914-a73e0fc29347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set cuda memcheck on\n",
            "set cuda api_failures stop\n",
            "catch throw\n",
            "r UNIT\n",
            "bt\n",
            "info locals\n",
            "thread 1\n",
            "bt\n",
            "Catchpoint 1 (throw)\n",
            "warning: Error disabling address space randomization: Operation not permitted\n",
            "[Thread debugging using libthread_db enabled]\n",
            "Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n",
            "[New Thread 0x7f386e370000 (LWP 2271)]\n",
            "[Detaching after fork from child process 2272]\n",
            "[New Thread 0x7f386d843000 (LWP 2277)]\n",
            "[New Thread 0x7f386d042000 (LWP 2278)]\n",
            "Time taken by CPU in milliseconds: 1648.68\n",
            "Max error: 0.000000\n",
            "Synchro\n",
            "GPU basic matrix multiplication in milliseconcs : 23.56\n",
            "Max error: 0.000000\n",
            "Synchro\n",
            "GPU tiled matrix multiplication in milliseconcs : 7.24\n",
            "Max error: 0.000000\n",
            "Synchro\n",
            "GPU cuBLAS matrix multiplication in milliseconcs : 1796.21\n",
            "Max error: 0.000000\n",
            "[Thread 0x7f386d843000 (LWP 2277) exited]\n",
            "[Thread 0x7f386e370000 (LWP 2271) exited]\n",
            "[Thread 0x7f38746ae000 (LWP 2266) exited]\n",
            "[Inferior 1 (process 2266) exited normally]\n",
            "tmp.txt:5: Error in sourced command file:\n",
            "No stack.\n"
          ]
        }
      ],
      "source": [
        "! printf \"set cuda memcheck on\\nset cuda api_failures stop\\ncatch throw\\nr UNIT\\nbt\\ninfo locals\\nthread 1\\nbt\\n\" > tmp.txt\n",
        "! cat tmp.txt\n",
        "! cuda-gdb -batch -x tmp.txt ./a.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGJ6uVNBVHUs",
        "outputId": "37e1e7f5-050c-497c-a0d9-31d8509b8d3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= COMPUTE-SANITIZER\n",
            "Time taken by CPU in milliseconds: 1108.46\n",
            "Max error: 0.000000\n",
            "Synchro\n",
            "GPU basic matrix multiplication in milliseconcs : 593.84\n",
            "Max error: 0.000000\n",
            "Synchro\n",
            "GPU tiled matrix multiplication in milliseconcs : 203.57\n",
            "Max error: 0.000000\n",
            "Synchro\n",
            "GPU cuBLAS matrix multiplication in milliseconcs : 5095.00\n",
            "Max error: 0.000000\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ],
      "source": [
        "!compute-sanitizer ./a.out \"UNIT\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17aUKkNJqTDZ"
      },
      "source": [
        "# Results\n",
        "\n",
        "Over 10 executions, the mean execution time obtained was :\n",
        "\n",
        "*   CPU : 1078 ms\n",
        "*   GPU basic : 23.94 ms\n",
        "*   GPU tiled : 10.74 ms (TILE_WIDTH=32) et 7.19 ms (TILE_WIDTH=16)\n",
        "*   GPU cublas : 319 ms\n",
        "\n",
        "The matrix multiplication is more efficient with GPU tiled configuration, and is even faster by diminushing TILE_WIDTH value"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "17aUKkNJqTDZ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}